# CleaningBotOld

2학년때 제작한, 학생회 사업중 하나인 과방 청소로봇이다.

(이 때는 정말 아무것도 몰라서 코드가 정리가 안 됐는데, 양해 부탁드립니다.)

나는 자율주행 파트를 맡았다.

자율주행 파트는 두 구성으로 나뉜다.

1. localization

2. 경로탐색

나는 주로 localization 파트를 맡았다.

카메라로 localization하기로 마음먹었는데,

이 당시에는 시간이 매우 한정적이어서, 당시 ROS를 다룰줄 몰랐던 나는 2d lidar를 이용하지 않았다.

대신 영상처리, 카메라를 사용하기로 마음먹었다.

우리 과방은 아래 사진과 같이 천장이 매우 특징적이다.

![3](https://user-images.githubusercontent.com/72921481/180732281-2c287820-2bb9-44a1-8497-72e582b025a3.png)

이를 이용해 localization하기로 마음먹었다.

계획은 다음과 같았다. :

0. 청소할 영역 기준 위치들과, 그곳에서 천장 사진들은 모두 로봇에 미리 저장되어있음. 지정된 초기 위치에서 청소 시작

1. 천장을 촬영하고, 이것과 0에서 미리 저장해둔 청소 영역 사진간 homography 관계 분석

2. 분석된 homography를 바탕으로 0에서의 기준위치와 현재 위치간 변위/상대회전 계산

3. 경로 탐색알고리즘으로 다음 청소영역 판단.

4. 2에서 분석된 변위/상대회전를 바탕으로, 다음 청소영역까지 얼마만큼 회전해야 하는지, 얼마만큼 직진해야 하는지 계산.

5. 회전 후 직진. 완료되면 1부터 반복

5에서 드리프트를 0에서 미리 지정해 둔 기준점을 바탕으로 2에서 global localization하는 셈이다.

하지만 이는 치명적인 단점이 존재했다.

우리 과방은 천장이 매우 울퉁불퉁하여 homography 관계를 분석하기 곤란하다는 점이다.

지금 와서 생각해보면 essential matrix 분석을 해야 했었다.

당시 시간이 없었던 우리는 다른 방법을 모색했다.

그 방법은 마커를 이용한 방법이다.

![1](https://user-images.githubusercontent.com/72921481/180732285-3eb671ad-5cd5-42f0-b207-63346c649b0c.jpg)

위와같이 천장에 삼각형 마커를 붙혀 이를 기준으로 기준점에 대한 변위/상대회전을 계산했다.
-> 다른 과방에서 진행하였다.

드리프트가 극심하지 않아 이미지 중심에 가까운 삼각형 마커만 취한다.

이 방법은 마커를 붙혀야 한다는 단점이 존재하지만, 그래도 0단계에서 모든 천장을 촬영할 필요는 없다는 장점이 있다.

당시에는 아무런 기반 지식도 없었지만, 지금와서 생각해보면 pseudo visual slam이었구나 느낀다.

아래는 로봇의 외형

![2](https://user-images.githubusercontent.com/72921481/180732268-5bec09c7-34fe-4039-92db-9888bc8abbed.png)
